{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Networks\n",
    "## What is Adversarial?\n",
    "![indiana](https://media.giphy.com/media/tivaSkhu8MbKM/giphy.gif)\n",
    "\n",
    "$\\min_{\\text{boulder}}\\max_{\\text{indiana}} V(\\text{indiana}, \\text{boulder}) = \\text{distance between them}$\n",
    "\n",
    "\n",
    "Estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model $G$ that captures the data distribution, and a discriminative model $D$ that estimates the probability that a sample came from the training data rather than $G$ (cite Goodfellow2014)\n",
    "\n",
    "![overviewgan](../images/overview.png \"https://arxiv.org/pdf/1710.07035.pdf\")\n",
    "\n",
    "Image from Creswell, A., White, T., Dumoulin, V., Arulkumaran, K., Sengupta, B. and Bharath, A.A., 2018. Generative adversarial networks: An overview. IEEE Signal Processing Magazine, 35(1), pp.53-65.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Notations\n",
    "\n",
    "- $x$ will be the **data element**.\n",
    "- $D(x)$ is the discriminator network which outputs the **probability that $x$ is real or generated**. $D(x)$ should be high when $x$ comes from training data and low when $x$ comes from the generator.\n",
    "- $z$ will be a **latent space vector** sampled from a normal distribution. $G(z)$ represents the generator function that which maps the latent vector $z$ to data-space. \n",
    "- The goal of $G$ is to estimate the distribution that the training data comes from ($p_{data}$) so it can generate fake samples from that estimated distribution ($p_g$).\n",
    "- $D(G(z))$ is the probability that the output of the generator $G$ is a real image. $D$ tries to **maximize the probability it correctly classifies reals and fakes** ($\\log D(x)$), and $G$ tries to **minimize the probability that $D$ will predict its outputs are fake** $(\\log (1 - D(G(x))$)\n",
    "\n",
    "$\\underset{G}{\\text{min}} \\underset{D}{\\text{max}}V(D,G) = \\mathbb{E}_{x\\sim p_{data}(x)}\\big[logD(x)\\big] + \\mathbb{E}_{z\\sim p_{z}(z)}\\big[log(1-D(G(x)))\\big]$\n",
    "\n",
    "![overviewgan](../images/datadist.png \"https://arxiv.org/pdf/1710.07035.pdf\")\n",
    "\n",
    "During GAN training, the generator is encouraged to produce a distribution of samples, $p_g(x)$ to match that of real data $p_{data}(x)$.\n",
    "\n",
    "In theory, the solution to this minimax game is where $p_g=p_{data}$, and the discriminator guesses randomly if the inputs are real or fake. However, the convergence theory of GANs is still being actively researched and in reality models do not always train to this point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Loop of GANs training\n",
    "\n",
    "![overviewgan](../images/mainloop.png \"https://arxiv.org/pdf/1710.07035.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Develop Deep Learning Models with Pytorch?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type of Layers\n",
    "- Conv\n",
    "- MaxPooling\n",
    "- BatchNorm\n",
    "- Upsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization & Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading and transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hands-on "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gantutorial",
   "language": "python",
   "name": "gantutorial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
